{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3872d2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-04T14:00:20.164418Z",
     "iopub.status.busy": "2022-11-04T14:00:20.163590Z",
     "iopub.status.idle": "2022-11-04T14:00:20.175972Z",
     "shell.execute_reply": "2022-11-04T14:00:20.174629Z"
    },
    "papermill": {
     "duration": 0.020497,
     "end_time": "2022-11-04T14:00:20.178858",
     "exception": false,
     "start_time": "2022-11-04T14:00:20.158361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1f0406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:00:20.186116Z",
     "iopub.status.busy": "2022-11-04T14:00:20.185754Z",
     "iopub.status.idle": "2022-11-04T14:00:20.191855Z",
     "shell.execute_reply": "2022-11-04T14:00:20.190602Z"
    },
    "papermill": {
     "duration": 0.012973,
     "end_time": "2022-11-04T14:00:20.194747",
     "exception": false,
     "start_time": "2022-11-04T14:00:20.181774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create a dataset exemple for decision tree.\n",
    "\n",
    "returns:\n",
    "    dataset: \n",
    "    labels:\n",
    "'''\n",
    "\n",
    "def createDataset():\n",
    "    dataset = DataFrame([[1, 1, 'yes'],\n",
    "                        [1, 1, 'yes'],\n",
    "                        [1, 0, 'no'],\n",
    "                        [0, 1, 'no'],\n",
    "                        [0, 1, 'no']], \n",
    "                        columns = ['no surfacing', 'flippers', 'label'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9cd9b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:00:20.201857Z",
     "iopub.status.busy": "2022-11-04T14:00:20.201451Z",
     "iopub.status.idle": "2022-11-04T14:00:20.209002Z",
     "shell.execute_reply": "2022-11-04T14:00:20.207708Z"
    },
    "papermill": {
     "duration": 0.014288,
     "end_time": "2022-11-04T14:00:20.211855",
     "exception": false,
     "start_time": "2022-11-04T14:00:20.197567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate the Shannon entropy.\n",
    "\n",
    "Calculate the Shannon entropy of the input dataset, in which \n",
    "the last column must be the label of each instance. Then return \n",
    "the shannon_entropy.\n",
    "\n",
    "parameters: \n",
    "    dataset: a DataFrame, the last column must be the label \n",
    "        of instance.\n",
    "    \n",
    "Returns: \n",
    "    shannonEnt: float. \n",
    "'''\n",
    "\n",
    "def calcShannonEnt(dataset):\n",
    "    label_counts = dataset.iloc[:, -1].value_counts()  # 计算类标签不同值出现的次数\n",
    "    shannon_entropy = 0.0\n",
    "    for label in label_counts.index:\n",
    "        prob = float(label_counts[label]) / len(dataset)\n",
    "        shannon_entropy -= prob * np.log2(prob)\n",
    "    return shannon_entropy\n",
    "\n",
    "# 利用pandas的广播特性直接对整个Series做除法，然后将prob和做点积并加上负号，即求得香农熵\n",
    "# def calcShannonEnt(dataset):\n",
    "#     label_counts = dataset.iloc[:, -1].value_counts()  # 计算类标签不同值出现的次数\n",
    "#     shannon_entropy = 0.0\n",
    "    \n",
    "#     prob = label_counts.astype(float) / len(my_dataset)\n",
    "#     shannon_entropy -= prob.dot(np.log2(prob))\n",
    "#     return shannon_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3061058d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:00:20.219520Z",
     "iopub.status.busy": "2022-11-04T14:00:20.219139Z",
     "iopub.status.idle": "2022-11-04T14:00:20.248729Z",
     "shell.execute_reply": "2022-11-04T14:00:20.247605Z"
    },
    "papermill": {
     "duration": 0.036155,
     "end_time": "2022-11-04T14:00:20.250730",
     "exception": false,
     "start_time": "2022-11-04T14:00:20.214575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = createDataset()\n",
    "calcShannonEnt(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2815bd05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:00:20.257631Z",
     "iopub.status.busy": "2022-11-04T14:00:20.257305Z",
     "iopub.status.idle": "2022-11-04T14:00:20.263197Z",
     "shell.execute_reply": "2022-11-04T14:00:20.262219Z"
    },
    "papermill": {
     "duration": 0.011552,
     "end_time": "2022-11-04T14:00:20.265146",
     "exception": false,
     "start_time": "2022-11-04T14:00:20.253594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Spliting the dataset.\n",
    "\n",
    "Deleting the best feature column of input dataset, and return rows, \n",
    "in which the best feature column's Series.values equal with input \n",
    "parameter value. \n",
    "\n",
    "Parameters:\n",
    "    dataset: DataFrame.\n",
    "    feature: label of DataFrame.\n",
    "    value: the value of the Series 'dataset[feature]'.\n",
    "\n",
    "Returns:\n",
    "    retDataset: DataFrame.\n",
    "    \n",
    "Exemple:\n",
    "    my_dataset\n",
    "    no surfacing\tflippers\tlabel\n",
    "    1\t1\tyes\n",
    "    1\t1\tyes\n",
    "    1\t0\tno\n",
    "    0\t1\tno\n",
    "    0\t1\tno\n",
    "    \n",
    "    my_dataset[my_dataset['flippers'] == 1]\n",
    "    no surfacing\tflippers\tlabel\n",
    "    1\t1\tyes\n",
    "    1\t1\tyes\n",
    "    0\t1\tno\n",
    "    0\t1\tno\n",
    "    \n",
    "    my_dataset[my_dataset['flippers'] == 0]\n",
    "    no surfacing\tflippers\tlabel\n",
    "    1\t0\tno\n",
    "'''\n",
    "\n",
    "def splitDataset(dataset, feature, value):\n",
    "    # dataset[dataset[feature] == value]利用布尔索引获取最优特征下不同取值所在的行。\n",
    "    retDataset = dataset[dataset[feature] == value].drop(labels=feature, axis='columns')\n",
    "    return retDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ed96f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:00:20.272310Z",
     "iopub.status.busy": "2022-11-04T14:00:20.271844Z",
     "iopub.status.idle": "2022-11-04T14:00:20.280304Z",
     "shell.execute_reply": "2022-11-04T14:00:20.279151Z"
    },
    "papermill": {
     "duration": 0.014997,
     "end_time": "2022-11-04T14:00:20.282939",
     "exception": false,
     "start_time": "2022-11-04T14:00:20.267942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Choose the best feature to split.\n",
    "\n",
    "Parameters:\n",
    "    dataset: DataFrame.\n",
    "        The last column should be the label of each instance.\n",
    "        \n",
    "Returns:\n",
    "    best_feature:\n",
    "        The best feature DataFrame.columns.\n",
    "'''\n",
    "\n",
    "def chooseBestFeatureToSplit(dataset):\n",
    "    entropy = calcShannonEnt(dataset)\n",
    "    best_info_gain = 0.0\n",
    "    best_feature = 0\n",
    "    for feature in dataset.columns[:-1]:  # 计算每个特征的信息增益，并将最优特征存入best_feature\n",
    "        unique_values = dataset[feature].unique()  # 特征的每一个可能取值\n",
    "        conditional_entropy = 0.0\n",
    "        for value in unique_values:  # 计算当前特征的条件熵\n",
    "            sub_dataset = splitDataset(dataset, feature, value)  # 当前特征将dataset划分为unique_values个子集\n",
    "            prob = len(sub_dataset) / len(dataset)\n",
    "            conditional_entropy -= prob * calcShannonEnt(sub_dataset)\n",
    "        info_gain = entropy - conditional_entropy  #当前特征的信息增益\n",
    "        if info_gain > best_info_gain:  #更新最优特征\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = feature\n",
    "    return best_feature\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32145d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:00:20.289916Z",
     "iopub.status.busy": "2022-11-04T14:00:20.289554Z",
     "iopub.status.idle": "2022-11-04T14:00:20.310250Z",
     "shell.execute_reply": "2022-11-04T14:00:20.309204Z"
    },
    "papermill": {
     "duration": 0.026316,
     "end_time": "2022-11-04T14:00:20.312165",
     "exception": false,
     "start_time": "2022-11-04T14:00:20.285849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flippers'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883329e",
   "metadata": {
    "papermill": {
     "duration": 0.002423,
     "end_time": "2022-11-04T14:00:20.317646",
     "exception": false,
     "start_time": "2022-11-04T14:00:20.315223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.692789,
   "end_time": "2022-11-04T14:00:21.042516",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-04T14:00:12.349727",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
