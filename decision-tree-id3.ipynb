{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8faaf3d5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.424843Z",
     "iopub.status.busy": "2022-11-05T03:10:12.424091Z",
     "iopub.status.idle": "2022-11-05T03:10:12.435397Z",
     "shell.execute_reply": "2022-11-05T03:10:12.434451Z"
    },
    "papermill": {
     "duration": 0.020256,
     "end_time": "2022-11-05T03:10:12.437815",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.417559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40380a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.446831Z",
     "iopub.status.busy": "2022-11-05T03:10:12.446463Z",
     "iopub.status.idle": "2022-11-05T03:10:12.455354Z",
     "shell.execute_reply": "2022-11-05T03:10:12.454343Z"
    },
    "papermill": {
     "duration": 0.015808,
     "end_time": "2022-11-05T03:10:12.457475",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.441667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create a dataset exemple for decision tree.\n",
    "\n",
    "returns:\n",
    "    dataset: \n",
    "    labels:\n",
    "'''\n",
    "\n",
    "def createDataset():\n",
    "#     dataset = DataFrame([[1, 1, 'yes'],\n",
    "#                         [1, 1, 'yes'],\n",
    "#                         [1, 0, 'no'],\n",
    "#                         [0, 1, 'no'],\n",
    "#                         [0, 1, 'no']], \n",
    "#                         columns = ['no surfacing', 'flippers', 'fish'])\n",
    "    \n",
    "    dataset = DataFrame([[0, 0, 0, 0, 'no'], \n",
    "            [0, 0, 0, 1, 'no'],\n",
    "            [0, 1, 0, 1, 'yes'],\n",
    "            [0, 1, 1, 0, 'yes'],\n",
    "            [0, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 1, 'no'],\n",
    "            [1, 1, 1, 1, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 1, 'yes'],\n",
    "            [2, 1, 0, 1, 'yes'],\n",
    "            [2, 1, 0, 2, 'yes'],\n",
    "            [2, 0, 0, 0, 'no']],\n",
    "            columns = ['年龄', '有工作', '有自己的房子', '信贷情况', '类别'])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37800944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.465542Z",
     "iopub.status.busy": "2022-11-05T03:10:12.465197Z",
     "iopub.status.idle": "2022-11-05T03:10:12.471912Z",
     "shell.execute_reply": "2022-11-05T03:10:12.470915Z"
    },
    "papermill": {
     "duration": 0.013204,
     "end_time": "2022-11-05T03:10:12.474051",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.460847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate the Shannon entropy.\n",
    "\n",
    "Calculate the Shannon entropy of the input dataset, in which \n",
    "the last column must be the label of each instance. Then return \n",
    "the shannon_entropy.\n",
    "\n",
    "parameters: \n",
    "    dataset: a DataFrame, the last column must be the label \n",
    "        of instance.\n",
    "    \n",
    "Returns: \n",
    "    shannonEnt: float. \n",
    "'''\n",
    "\n",
    "def calcShannonEnt(dataset):\n",
    "    label_counts = dataset.iloc[:, -1].value_counts()  # 计算类标签不同值出现的次数\n",
    "    shannon_entropy = 0.0\n",
    "    for label in label_counts.index:\n",
    "        prob = float(label_counts[label]) / len(dataset)\n",
    "        shannon_entropy -= prob * np.log2(prob)\n",
    "    return shannon_entropy\n",
    "\n",
    "# 利用pandas的广播特性直接对整个Series做除法，然后将prob和做点积并加上负号，即求得香农熵\n",
    "# def calcShannonEnt(dataset):\n",
    "#     label_counts = dataset.iloc[:, -1].value_counts()  # 计算类标签不同值出现的次数\n",
    "#     shannon_entropy = 0.0\n",
    "    \n",
    "#     prob = label_counts.astype(float) / len(my_dataset)\n",
    "#     shannon_entropy -= prob.dot(np.log2(prob))\n",
    "#     return shannon_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e8d11d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.481883Z",
     "iopub.status.busy": "2022-11-05T03:10:12.481531Z",
     "iopub.status.idle": "2022-11-05T03:10:12.513902Z",
     "shell.execute_reply": "2022-11-05T03:10:12.512426Z"
    },
    "papermill": {
     "duration": 0.039253,
     "end_time": "2022-11-05T03:10:12.516647",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.477394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = createDataset()\n",
    "calcShannonEnt(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff322da5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.526152Z",
     "iopub.status.busy": "2022-11-05T03:10:12.525516Z",
     "iopub.status.idle": "2022-11-05T03:10:12.531766Z",
     "shell.execute_reply": "2022-11-05T03:10:12.530669Z"
    },
    "papermill": {
     "duration": 0.013297,
     "end_time": "2022-11-05T03:10:12.533941",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.520644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Spliting the dataset.\n",
    "\n",
    "Deleting the best feature column of input dataset, and return rows, \n",
    "in which the best feature column's Series.values equal with input \n",
    "parameter value. \n",
    "\n",
    "Parameters:\n",
    "    dataset: DataFrame.\n",
    "    feature: label of DataFrame.\n",
    "    value: the value of the Series 'dataset[feature]'.\n",
    "\n",
    "Returns:\n",
    "    retDataset: DataFrame.\n",
    "    \n",
    "Exemple:\n",
    "    my_dataset\n",
    "    no surfacing\tflippers\tlabel\n",
    "    1\t1\tyes\n",
    "    1\t1\tyes\n",
    "    1\t0\tno\n",
    "    0\t1\tno\n",
    "    0\t1\tno\n",
    "    \n",
    "    my_dataset[my_dataset['flippers'] == 1]\n",
    "    no surfacing\tflippers\tlabel\n",
    "    1\t1\tyes\n",
    "    1\t1\tyes\n",
    "    0\t1\tno\n",
    "    0\t1\tno\n",
    "    \n",
    "    my_dataset[my_dataset['flippers'] == 0]\n",
    "    no surfacing\tflippers\tlabel\n",
    "    1\t0\tno\n",
    "'''\n",
    "\n",
    "def splitDataset(dataset, feature, value):\n",
    "    # dataset[dataset[feature] == value]利用布尔索引获取最优特征下不同取值所在的行。\n",
    "    retDataset = dataset[dataset[feature] == value].drop(labels=feature, axis='columns')\n",
    "    return retDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5471535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.542706Z",
     "iopub.status.busy": "2022-11-05T03:10:12.542349Z",
     "iopub.status.idle": "2022-11-05T03:10:12.550374Z",
     "shell.execute_reply": "2022-11-05T03:10:12.549117Z"
    },
    "papermill": {
     "duration": 0.015148,
     "end_time": "2022-11-05T03:10:12.552647",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.537499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Choose the best feature to split.\n",
    "\n",
    "Parameters:\n",
    "    dataset: DataFrame.\n",
    "        The last column should be the label of each instance.\n",
    "        \n",
    "Returns:\n",
    "    best_feature:\n",
    "        The best feature DataFrame.columns.\n",
    "'''\n",
    "\n",
    "def chooseBestFeatureToSplit(dataset):\n",
    "    entropy = calcShannonEnt(dataset)\n",
    "    best_info_gain = 0.0\n",
    "    best_feature = 0\n",
    "    for feature in dataset.columns[:-1]:  # 计算每个特征的信息增益，并将最优特征存入best_feature\n",
    "        unique_values = dataset[feature].unique()  # 特征的每一个可能取值\n",
    "        conditional_entropy = 0.0\n",
    "        for value in unique_values:  # 计算当前特征的条件熵\n",
    "            sub_dataset = splitDataset(dataset, feature, value)  # 当前特征将dataset划分为unique_values个子集\n",
    "            prob = len(sub_dataset) / len(dataset)\n",
    "            '''\n",
    "            calcShannonEnt在计算香农熵时已经带了负号，\n",
    "            因此此处计算条件熵时不能用-=。\n",
    "            conditional_entropy -= prob * calcShannonEnt(sub_dataset)\n",
    "            '''\n",
    "            conditional_entropy += prob * calcShannonEnt(sub_dataset)\n",
    "        info_gain = entropy - conditional_entropy  #当前特征的信息增益\n",
    "        if info_gain > best_info_gain:  #更新最优特征\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = feature\n",
    "    return best_feature\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e82842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.561679Z",
     "iopub.status.busy": "2022-11-05T03:10:12.560945Z",
     "iopub.status.idle": "2022-11-05T03:10:12.566838Z",
     "shell.execute_reply": "2022-11-05T03:10:12.566136Z"
    },
    "papermill": {
     "duration": 0.012806,
     "end_time": "2022-11-05T03:10:12.569023",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.556217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Return the majority class of current dataset.\n",
    "\n",
    "This function is used when all features are iterated and \n",
    "the columns of dataset only have class_label. Then decision \n",
    "tree returns the majority count class as leaf node.\n",
    "\n",
    "Parameters:\n",
    "    dataset: DataFrame.\n",
    "        Only have the class_label column.\n",
    "        \n",
    "Returns:\n",
    "    majority_class:\n",
    "        Majority count value of class_label.\n",
    "\n",
    "'''\n",
    "\n",
    "def majorityCount(dataset):\n",
    "    # 对class label计数并降序排列，返回第一个index。\n",
    "    class_count = dataset.iloc[:, -1].value_counts().sort_values(ascending=False)\n",
    "    majority_class = class_count.index[0]\n",
    "    return majority_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e595e9a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.577890Z",
     "iopub.status.busy": "2022-11-05T03:10:12.577300Z",
     "iopub.status.idle": "2022-11-05T03:10:12.584556Z",
     "shell.execute_reply": "2022-11-05T03:10:12.583813Z"
    },
    "papermill": {
     "duration": 0.014079,
     "end_time": "2022-11-05T03:10:12.586637",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.572558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create decision tree.\n",
    "\n",
    "Parameters:\n",
    "    dataset: DataFrame.\n",
    "        \n",
    "Returns:\n",
    "    decision_tree: a python dict.\n",
    "\n",
    "'''\n",
    "\n",
    "def createTree(dataset):\n",
    "    if dataset.iloc[:, -1].nunique() == 1:  # 只剩一个类别，停止划分\n",
    "        return dataset.iloc[:, -1].unique()[0]  # 返回类标签的具体值，即叶子节点\n",
    "    if len(dataset.columns) == 1:  # 遍历完所有特征，此时dataset中只剩下label_class列\n",
    "        return majorityCount(dataset)\n",
    "    best_feature = chooseBestFeatureToSplit(dataset)\n",
    "    '''\n",
    "    使用python字典构建决策树，\n",
    "    e.g. decision_tree = {best_feature: {}}\n",
    "    decision_tree[best_feature]为上式中的{}，\n",
    "    decision_tree[best_feature][value] = createTree(sub_dataset)在{}中生成子节点，\n",
    "    其中value为最优特征的取值，它将数据集分为dataset[best_feature].unique()个子集。\n",
    "    在这些子集中递归调用createTree。\n",
    "    如'flippers': {1: 'yes', 0: 'no'}中，\n",
    "    最优特征有两个取值1和0，因此'flippers'之下有两个子集，\n",
    "    在此例中，两个子集中均为一个类别，所以这两个子集分别生成一个叶子节点'yes','no'。\n",
    "    '''\n",
    "    decision_tree = {best_feature: {}}\n",
    "    # 在最优特征下递归调用createTree，继续生成内部节点，直到满足两个if终止条件，生成叶子节点\n",
    "    for value in dataset[best_feature].unique():  \n",
    "        sub_dataset = splitDataset(dataset, best_feature, value)\n",
    "        decision_tree[best_feature][value] = createTree(sub_dataset)\n",
    "    return decision_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e685438b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T03:10:12.595538Z",
     "iopub.status.busy": "2022-11-05T03:10:12.594901Z",
     "iopub.status.idle": "2022-11-05T03:10:12.637873Z",
     "shell.execute_reply": "2022-11-05T03:10:12.636863Z"
    },
    "papermill": {
     "duration": 0.050112,
     "end_time": "2022-11-05T03:10:12.640330",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.590218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'有自己的房子': {0: {'有工作': {0: 'no', 1: 'yes'}}, 1: 'yes'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createTree(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24b6c7",
   "metadata": {
    "papermill": {
     "duration": 0.003482,
     "end_time": "2022-11-05T03:10:12.647496",
     "exception": false,
     "start_time": "2022-11-05T03:10:12.644014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.655269,
   "end_time": "2022-11-05T03:10:13.272251",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-05T03:10:03.616982",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
